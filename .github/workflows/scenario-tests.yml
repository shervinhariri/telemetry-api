name: scenario-tests
on:
  push:
    branches: [ main, 'fix/**' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch: {}

jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Build image from source
        run: docker compose build

      - name: Start e2e stack
        env:
          TELEMETRY_DLQ_DIR: /tmp/dlq
        run: |
          docker compose down || true
          # Load test environment variables (skip comments)
          export $(grep -v '^#' .github/test.env | xargs)
          echo "Loaded env vars: TELEMETRY_SEED_KEYS=$TELEMETRY_SEED_KEYS"
          # Start using docker compose (builds from source) - ignore override file
          docker compose -f docker-compose.yml up -d
          echo "Waiting for API to become healthy (up to 80s)..."
          ok=0
          for i in $(seq 1 40); do
            if docker exec telemetry-api python -c "import urllib.request, sys; sys.exit(0 if urllib.request.urlopen('http://127.0.0.1:80/v1/health').status == 200 else 1)" 2>/dev/null
            then
              echo "API healthy"
              ok=1
              break
            fi
            sleep 2
          done
          [ "$ok" = "1" ] || { docker compose ps; docker compose logs --tail 300; exit 1; }
          
          # Wait additional time for database initialization to complete
          echo "Waiting for database initialization to complete..."
          sleep 10
          
          # Ensure database migration runs
          echo "Running database migration..."
          docker exec telemetry-api python scripts/migrate_sqlite.py
          
          # Wait for API to be fully ready and database to be populated
          echo "Waiting for API to be fully ready..."
          max_wait=30
          for i in $(seq 1 $max_wait); do
              if docker exec telemetry-api python -c "import sqlite3; conn = sqlite3.connect('/data/telemetry.db'); cursor = conn.cursor(); cursor.execute('SELECT COUNT(*) FROM api_keys'); count = cursor.fetchone()[0]; conn.close(); print(f'Found {count} api_keys'); exit(0 if count > 0 else 1)" 2>/dev/null; then
                  echo "API is ready with api_keys table populated"
                  break
              fi
              echo "Waiting for API to be ready... (attempt $i/$max_wait)"
              sleep 2
          done

      - name: Sanity check container
        run: |
          docker exec telemetry-api python -c "import sqlite3; print('sqlite3 OK')"
          docker exec telemetry-api python -c "from app.main import app; print('app OK')"

      - name: DB check (verify scopes format)
        run: |
          docker exec telemetry-api bash -lc 'python - <<"PY"
          from sqlalchemy import create_engine, text
          import os, json, time
          db=os.getenv("DB_URL","sqlite:////data/telemetry.db")
          e=create_engine(db, future=True)
          
          # Wait for api_keys table to exist
          max_retries = 10
          for attempt in range(max_retries):
              try:
                  with e.connect() as c:
                      # First check what tables exist
                      tables = c.execute(text("SELECT name FROM sqlite_master WHERE type=:type"), {"type": "table"}).all()
                      print(f"Available tables: {[t[0] for t in tables]}")
                      
                      rows=c.execute(text("select key_id, scopes from api_keys limit 3;")).all()
                      print("DB scopes check:")
                      for row in rows:
                          print(f"  {row[0]}: {row[1]}")
                      break
              except Exception as exc:
                  if attempt < max_retries - 1:
                      print(f"Waiting for api_keys table (attempt {attempt + 1}/{max_retries})...")
                      time.sleep(2)
                  else:
                      print(f"Failed to find api_keys table after {max_retries} attempts")
                      raise
          PY'

      # Run tests against the running container
      - name: Run tests against container
        run: |
          # Wait for container to be ready
          sleep 5
          # Run tests using the test client
          python -m pytest tests/ -v

      - name: Scenario tester
        env:
          API_BASE_URL: http://localhost:80
          API_KEY: TEST_ADMIN_KEY
        run: |
          python tools/scenario_tester.py | tee scenario_report.json
          echo "---- Summary ----"
          jq '.results[] | {scenario, status, ok}' scenario_report.json

      - name: Dump logs on failure
        if: failure()
        run: |
          docker compose ps
          docker compose logs --no-color | tail -n 500
          echo "=== Database contents ==="
          docker exec telemetry-api bash -lc 'python - <<"PY"
          from sqlalchemy import create_engine, text
          import os
          db=os.getenv("DB_URL","sqlite:////data/telemetry.db")
          e=create_engine(db, future=True)
          try:
              with e.connect() as c:
                  rows=c.execute(text("SELECT key_id, scopes, disabled FROM api_keys;")).all()
                  for row in rows:
                      print(f"  {row[0]}: {row[1]} (disabled={row[2]})")
          except Exception as exc:
              print(f"Error querying api_keys table: {exc}")
              # Show available tables
              try:
                  with e.connect() as c:
                      tables=c.execute(text("SELECT name FROM sqlite_master WHERE type=:type"), {"type": "table"}).all()
                      print(f"Available tables: {[t[0] for t in tables]}")
              except Exception as table_exc:
                  print(f"Error querying available tables: {table_exc}")
          PY'

      - name: Upload report artifact
        uses: actions/upload-artifact@v4
        with:
          name: scenario-report
          path: scenario_report.json


